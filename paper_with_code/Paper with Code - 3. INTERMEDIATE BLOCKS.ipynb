{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. INTERMEDIATE BLOCKS\n",
    "\n",
    "\n",
    "\n",
    "We present several types of intermediate blocks based on different design strategies. We first present time-distributed blocks and then present time-frequency blocks.\n",
    "\n",
    "\n",
    "### 3.1 Time-Distributed Blocks\n",
    "\n",
    "Some existing models use CNNs (e.g., [16]) for intermediate blocks to extract timbre features of the target source.\n",
    "However, the authors of [8] reported that conventional CNN kernels are limited for this task.\n",
    "They found that long-range correlations exist along the frequency axis in the spectrogram of voice signals, which Fully-connected Neural Networks (FCNs) can efficiently capture.\n",
    "They proposed a model named Phasen for speech enhancement, which uses the Frequency Transformation Block (FTB) that has a single-layered FCN without bias. This FCN is applied to each frame of the internal representation in a **time-distributed** manner.\n",
    "\n",
    "\n",
    "Inspired by TFB, we introduce **time-distributed** blocks, which are applied to a single frame of a spectrogram-like feature map. These blocks try to extract time-independent features that help singing voice separation without using inter-frame operations.\n",
    "We first introduce an FCN-based block and then propose an alternative time-distributed block based on 1-D CNNs. \n",
    "\n",
    "\n",
    "\n",
    "#### 3.1.1 Time-Distributed Fully-connected networks\n",
    "\n",
    "We present an FCN-based intermediate block, called Time-Distributed Fully-connected network (TDF). \n",
    "As illustrated in Figure 3, a TDF block is applied to each channel of each frame separately and identically. \n",
    "\n",
    "![](img/tdf.png)\n",
    "Figure 3. Time-Distributed Fully-connected network\n",
    "\n",
    "Suppose that the $l$-th intermediate block in our U-Net structure takes input $X^{(l-1)}$ into an output $X^{(l)}$.\n",
    "As shown in Figure 3, a  fully-connected network is applied separately and identically to each frame (i.e., $X^{(l-1)}[i,j,:]$) in order to transform an input tensor in a time-distributed fashion. \n",
    "While an FTB of Phasen [8] is single-layered, a TDF block can be either single- or multi-layered. Each layer is defined as consecutive operations: a fully-connected layer, Batch Norm (BN) [17], and ReLU [15]. If it is multi-layered, then each internal layer maps an input to the hidden feature space, and its final layer maps the internal vector to $\\mathbb{R}^{F^{(l)}}$.\n",
    "The number of hidden units is $\\lfloor F^{(l)}/bn \\rfloor$, where we denote the bottleneck factor by $bf$. We can reduce parameters if we use two-layered TDFs of $bf > 2$. We investigate the effect of adding additional layers in ยง4.2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class TDF(nn.Module):\n",
    "    ''' [B, in_channels, T, F] => [B, in_channels, T, F] '''\n",
    "    def __init__(self, channels, f, bf=16, bias=False, min_bn_units=16):\n",
    "        \n",
    "        '''\n",
    "        channels: # channels\n",
    "        f: num of frequency bins\n",
    "        bf: bottleneck factor. if None: single layer. else: MLP that maps f => f//bf => f \n",
    "        bias: bias setting of linear layers\n",
    "        '''\n",
    "        \n",
    "        super(TDF, self).__init__()\n",
    "\n",
    "        if(bf is None):\n",
    "            self.tdf = nn.Sequential(\n",
    "                nn.Linear(f,f, bias),\n",
    "                nn.BatchNorm2d(channels),\n",
    "                nn.ReLU()\n",
    "            )\n",
    "        \n",
    "        else:\n",
    "            bn_unis = max(f//bf, min_bn_units)\n",
    "            self.tdf = nn.Sequential(\n",
    "                nn.Linear(f,bn_unis, bias),\n",
    "                nn.BatchNorm2d(channels),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(bn_unis,f,bias),\n",
    "                nn.BatchNorm2d(channels),\n",
    "                nn.ReLU()\n",
    "            )\n",
    "            \n",
    "    def forward(self, x):\n",
    "        return self.tdf(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1.2 Time-Distributed Convolutions\n",
    "\n",
    "\n",
    "We propose an alternative time-distributed block named Time-Distributed Convolutions (TDC), which is applied separately and identically to each multi-channeled frame. \n",
    "It is a series of 1-D convolution layers.\n",
    "Inspired by [5,6], it takes form of a **dense block** [18] structure. A dense block consists of densely connected composite layers, where each composite layer is defined as three consecutive operations: 1-D convolution, BN, and ReLU.\n",
    "As discussed in [5,6,18] the densely connected structure enables each layer to propagate the gradient directly to all preceding layers, making a deep CNN training more efficient. \n",
    "\n",
    "\n",
    "![](img/tdc.png)\n",
    "Figure 4. Time-Distributed Convolutions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TDC(nn.Module):\n",
    "    '''\n",
    "    [B, in_channels, T, F] => [B, out_channels (= gr), T, F] \n",
    "    We set the number of output channels to be the same as the growth rate\n",
    "    '''\n",
    "    def __init__(self, in_channels, num_layers, gr, kf):\n",
    "        \n",
    "        '''\n",
    "        in_channels: number of input channels\n",
    "        num_layers: number of densly connected conv layers\n",
    "        gr: growth rate\n",
    "        kf: kernal size of the freq. axis\n",
    "        '''\n",
    "        \n",
    "        super(TDC, self).__init__()\n",
    "\n",
    "        c = in_channels\n",
    "        self.H = nn.ModuleList()\n",
    "        for i in range(num_layers):\n",
    "            self.H.append(\n",
    "                nn.Sequential(\n",
    "                    nn.Conv1d(in_channels=c, out_channels=gr,kernel_size=kf,stride=1,padding=kf//2),\n",
    "                    nn.BatchNorm1d(gr),\n",
    "                    nn.ReLU(),\n",
    "                )\n",
    "            )\n",
    "            c += gr\n",
    "\n",
    "    def forward(self, x):\n",
    "        '''[B, in_channels, T, F] => [B, out_channels (= gr), T, F] '''\n",
    "        \n",
    "        B, _, T, F = x.shape\n",
    "        x = x.transpose(-2,-3)   # B, T, c, F\n",
    "        x = x.reshape(B*T,-1,F)  # BT, c, F\n",
    "        \n",
    "        x_ = self.H[0](x)\n",
    "        for h in self.H[1:]:\n",
    "            x = torch.cat((x_, x), 1)\n",
    "            x_ = h(x)  \n",
    "\n",
    "        x_ = x_.view(B,T,-1,F)   # B, T, c, F\n",
    "        x_ = x_.transpose(-2,-3) # B, c, T, F\n",
    "        return x_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Time-Frequency Blocks\n",
    "\n",
    "The performances of U-Nets with time-distributed blocks were above our expectation (see ยง4.2), but were still inferior considerably to those of current SOTA methods. The reason is that features observed in musical sources include sequential patterns (e.g., vibrato, tremolo, and crescendo) or musical patterns (e.g., rhythm, repetitive structure), which cannot be modeled by time-distributed blocks.\n",
    "\n",
    "While time-distributed blocks cannot model the temporal context, time-frequency blocks try to extract features considering both the time and the frequency dimensions.\n",
    "We introduce the Time-Frequency Convolutions (TFC) block, which is used in [5]. \n",
    "We also propose two novel blocks that combine two different transformations.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#### 3.2.1 Time-Frequency Convolutions\n",
    "\n",
    "The Time-Frequency Convolutions (TFC) is a dense block of 2-D CNNs, as shown in Figure 5.\n",
    "The dense block consists of densely connected composite layers, where each layer is defined as three consecutive operations: 2-D convolution, BN, and ReLU.   \n",
    "It is applied to the spectrogram-like input representation in the time-frequency domain.\n",
    "Every convolution layer in a dense block has kernels of size $(k_F, k_T)$. Its 2-D filters are trained to jointly capture features along both frequency and temporal axes.\n",
    "\n",
    "![](img/tfc.png)\n",
    "\n",
    "Figure 5. Time-Frequency Convolutions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TFC(nn.Module):\n",
    "    '''\n",
    "    [B, in_channels, T, F] => [B, out_channels (= gr), T, F] \n",
    "    We set the number of output channels to be the same as the growth rate\n",
    "    '''\n",
    "    def __init__(self, in_channels, num_layers, gr, kt, kf):\n",
    "        '''\n",
    "        in_channels: number of input channels\n",
    "        num_layers: number of densly connected conv layers\n",
    "        gr: growth rate\n",
    "        kt: kernal size of the temporal axis.        \n",
    "        kf: kernal size of the freq. axis\n",
    "        '''\n",
    "        \n",
    "        super(TFC, self).__init__()\n",
    "        c = in_channels\n",
    "        self.H = nn.ModuleList()\n",
    "        for i in range(num_layers):\n",
    "            self.H.append(\n",
    "                nn.Sequential(\n",
    "                    nn.Conv2d(in_channels=c, out_channels=gr, kernel_size=(kf, kt), stride=1, padding=(kt//2, kf//2)),\n",
    "                    nn.BatchNorm2d(gr),\n",
    "                    nn.ReLU(),\n",
    "                )\n",
    "            )\n",
    "            c += gr\n",
    "\n",
    "    def forward(self, x):\n",
    "        ''' [B, in_channels, T, F] => [B, gr, T, F] '''\n",
    "        x_ = self.H[0](x)\n",
    "        for h in self.H[1:]:\n",
    "            x = torch.cat((x_, x), 1)\n",
    "            x_ = h(x)  \n",
    "\n",
    "        return x_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2.2 Time-Frequency Convolutions with TDF\n",
    "\n",
    "\n",
    "We propose the Time-Frequency Convolutions with Time-Distributed Fully-connected networks (TFC-TDF) block. \n",
    "It utilizes two different blocks inside: a TFC block and a TDF block.\n",
    "Figure 6 describes a TFC-TDF block.\n",
    "It first maps the input $X^{(l-1)}$ to a same-sized representation with $c_{out}^{(l)}$ channels by applying the TFC block. Then the TDF block is applied to the dense block output. A residual connection is also added for efficient gradient flow.\n",
    "\n",
    "![](img/tfctdf.png)\n",
    "Figure 6. Time-Frequency Convolutions with TDF\n",
    "\n",
    "Phasen [8] has shown that inserting time-distributed operations into intermediate blocks can improve speech enhancement performance.\n",
    "We validate whether it also works for SVS or not in ยง4.3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TFC_TDF(nn.Module):\n",
    "    '''\n",
    "    [B, in_channels, T, F] => [B, out_channels (= gr), T, F] \n",
    "    We set the number of output channels to be the same as the growth rate\n",
    "    '''\n",
    "    def __init__(self, in_channels, num_layers, gr, kt, kf, f, bf=16, bias=True):\n",
    "        '''\n",
    "        in_channels: number of input channels\n",
    "        num_layers: number of densly connected conv layers\n",
    "        gr: growth rate\n",
    "        kt: kernal size of the temporal axis.        \n",
    "        kf: kernal size of the freq. axis\n",
    "        f: num of frequency bins\n",
    "        \n",
    "        below are params for TDF \n",
    "        bf: bottleneck factor. if None: single layer. else: MLP that maps f => f//bf => f \n",
    "        bias: bias setting of linear layers\n",
    "        '''\n",
    "        \n",
    "        super(TFC_TDF, self).__init__()\n",
    "        self.tfc = TFC(in_channels, num_layers, gr, kt, kf)\n",
    "        self.tdf = TDF(gr, f, bf, bias)\n",
    "            \n",
    "    def forward(self, x):\n",
    "        x = self.tfc(x)\n",
    "        \n",
    "        return x + self.tdf(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2.3 Time-Distributed Convolutions with RNNs\n",
    "\n",
    "We propose an alternative way to consider both the time and frequency dimensions.\n",
    "A Time-Distributed Convolutions with Recurrent Neural Networks (TDC-RNN) block uses two different blocks: a TDC block for extracting timbre features and RNNs for capturing temporal patterns.\n",
    "It extracts timbre features and temporal features **separately**, unlike a TFC block. We validate whether this approach can outperform the 2-D CNN approach by comparing TDC-RNNs with TFCs in ยง4.3.\n",
    "\n",
    "The structure of a TDC-RNN block is similar to that of a TFC-TDF block.\n",
    "It applies the TDC block to an input $X^{(l-1)}$, and obtains a same sized hidden representation with  $c_{out}^{(l)}$ channels. The RNNs compute the hidden representation and output an equally sized tensor. A residual connection is added, as is a TFC-TDF block.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TDC_RNN(nn.Module):\n",
    "    '''\n",
    "    [B, in_channels, T, F] => [B, out_channels (= gr), T, F] \n",
    "    We set the number of output channels to be the same as the growth rate\n",
    "    '''\n",
    "    def __init__(self, \n",
    "                 in_channels, \n",
    "                 num_layers_tdc, gr, kf, f, \n",
    "                 bn_factor_rnn, num_layers_rnn, bidirectional=True, min_bn_units_rnn=16, bias_rnn=True,  ## RNN params\n",
    "                 bn_factor_tif=16, bias_tif=True, ## RNN params\n",
    "                 skip_connection=True):\n",
    "        \n",
    "        '''\n",
    "        in_channels: number of input channels\n",
    "        num_layers_tdc: number of densly connected conv layers\n",
    "        gr: growth rate\n",
    "        kf: kernal size of the freq. axis\n",
    "        f: # freq bins\n",
    "        bn_factor_rnn: bottleneck factor of rnn \n",
    "        num_layers_rnn: number of layers of rnn\n",
    "        bidirectional: if true then bidirectional version rnn \n",
    "        bn_factor_tif: bottleneck factor of tif\n",
    "        bias: bias\n",
    "        skip_connection: if true then tdc+rnn else rnn\n",
    "        '''\n",
    "        \n",
    "        super(TDC_RNN, self).__init__()\n",
    "\n",
    "        self.skip_connection = skip_connection\n",
    "        \n",
    "        self.tdc = TDC(in_channels, num_layers_tdc, gr, kf)\n",
    "        self.bn = nn.BatchNorm2d(gr)\n",
    "        \n",
    "        hidden_units_rnn = max(f//bn_factor_rnn, min_bn_units_rnn)\n",
    "        self.rnn = nn.GRU(f, hidden_units_rnn, num_layers_rnn, bias=bias_rnn, batch_first=True, bidirectional=bidirectional)\n",
    "        \n",
    "        f_from = hidden_units_rnn * 2 if bidirectional else hidden_units_rnn\n",
    "        f_to = f\n",
    "        self.tif_f1_to_f2 = TIF_f1_to_f2(gr, f_from, f_to, bn_factor=bn_factor_tif, bias=bias_tif)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        ''' [B, in_channels, T, F] => [B, gr, T, F] '''\n",
    "        \n",
    "        x = self.tdc(x) # [B, in_channels, T, F] => [B, gr, T, F]\n",
    "        x = self.bn(x)  # [B, gr, T, F] => [B, gr, T, F]\n",
    "        tdc_output = x\n",
    "\n",
    "        B, C, T, F = x.shape\n",
    "        x = x.view(-1, T, F)\n",
    "        x, _ = self.rnn(x)       # [B * gr, T, F] => [B * gr, T, 2*hidden_size]\n",
    "        x = x.view(B,C,T, -1)    # [B * gr, T, 2*hidden_size] => [B, gr, T, 2*hidden_size]\n",
    "        rnn_output = self.tif_f1_to_f2(x) # [B, gr, T, 2*hidden_size] => [B, gr, T, F]\n",
    "        \n",
    "        return tdc_output + rnn_output if self.skip_connection else rnn_output"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
